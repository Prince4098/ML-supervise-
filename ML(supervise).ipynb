{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658b8613",
   "metadata": {},
   "source": [
    "# Loding Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ee5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518dd84f",
   "metadata": {},
   "source": [
    "# 1st way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b15759",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19128132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
      "        1.065e+03],\n",
      "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
      "        1.050e+03],\n",
      "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
      "        1.185e+03],\n",
      "       ...,\n",
      "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
      "        8.350e+02],\n",
      "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
      "        8.400e+02],\n",
      "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
      "        5.600e+02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2]), 'frame': None, 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'), 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n', 'feature_names': ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c2b4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5d3d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\Users\\\\Prince\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a81c5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# printing all data points against indicator variables\n",
    "\n",
    "print(dataset_wine.data)\n",
    "\n",
    "# printing all data points against predictive  variable\n",
    "\n",
    "print(dataset_wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86a97bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset\n",
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"size of dataset\")\n",
    "print(dataset_wine.data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61e3482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sizz of the target feature\n",
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "print(\"the sizz of the target feature\")\n",
    "print(dataset_wine.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "735ae0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of features as as below\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "print(\"The name of features as as below\")\n",
    "print(dataset_wine.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5221634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of classes in target feature\n",
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print(\"The name of classes in target feature\")\n",
    "print(dataset_wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172db1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample data of first 5 data points is as below\n",
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The sample data of first 5 data points is as below\")\n",
    "print(dataset_wine.data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8049020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample target values of first 5 data points is as below\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"The sample target values of first 5 data points is as below\")\n",
    "print(dataset_wine.target[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee57f8b",
   "metadata": {},
   "source": [
    "# 2. Loading User choice data set  in scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b27aba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a074acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data set from local machine\n",
    "My_dataset = pd.read_csv('C:/Users/Prince/Desktop/amity programing/CSV files/liver_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "120e6d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcv</th>\n",
       "      <th>alkphos</th>\n",
       "      <th>sgpt</th>\n",
       "      <th>sgot</th>\n",
       "      <th>gammagt</th>\n",
       "      <th>drink</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>99</td>\n",
       "      <td>75</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>96</td>\n",
       "      <td>69</td>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "      <td>203</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>98</td>\n",
       "      <td>77</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>89</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>91</td>\n",
       "      <td>68</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>57</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mcv  alkphos  sgpt  sgot  gammagt  drink  target\n",
       "0     85       92    45    27       31    0.0       1\n",
       "1     85       64    59    32       23    0.0       2\n",
       "2     86       54    33    16       54    0.0       2\n",
       "3     91       78    34    24       36    0.0       2\n",
       "4     87       70    12    28       10    0.0       2\n",
       "..   ...      ...   ...   ...      ...    ...     ...\n",
       "340   99       75    26    24       41   12.0       1\n",
       "341   96       69    53    43      203   12.0       2\n",
       "342   98       77    55    35       89   15.0       1\n",
       "343   91       68    27    26       14   16.0       1\n",
       "344   98       99    57    45       65   20.0       1\n",
       "\n",
       "[345 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be7bf8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcv</th>\n",
       "      <th>alkphos</th>\n",
       "      <th>sgpt</th>\n",
       "      <th>sgot</th>\n",
       "      <th>gammagt</th>\n",
       "      <th>drink</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcv  alkphos  sgpt  sgot  gammagt  drink  target\n",
       "0   85       92    45    27       31    0.0       1\n",
       "1   85       64    59    32       23    0.0       2\n",
       "2   86       54    33    16       54    0.0       2\n",
       "3   91       78    34    24       36    0.0       2\n",
       "4   87       70    12    28       10    0.0       2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1ae9be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data set\n",
      "(345, 7)\n",
      "The data values of first 4 data points are as below(excluding target variable)\n",
      "[[85. 92. 45. 27. 31.  0.]\n",
      " [85. 64. 59. 32. 23.  0.]\n",
      " [86. 54. 33. 16. 54.  0.]\n",
      " [91. 78. 34. 24. 36.  0.]]\n",
      "The class values of first 4 data points are as below\n",
      "[1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Understanding data set\n",
    "print(\"The size of the data set\")\n",
    "print(My_dataset.shape)\n",
    "print(\"The data values of first 4 data points are as below(excluding target variable)\")\n",
    "print(My_dataset.iloc[0:4,0:6].values)\n",
    "print(\"The class values of first 4 data points are as below\")\n",
    "print(My_dataset.iloc[0:4,6].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08171564",
   "metadata": {},
   "source": [
    "# loding data set end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661288f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4004c89b",
   "metadata": {},
   "source": [
    "# Creating Hold-out enviornment for Model learning and testing\n",
    "\n",
    "In Hold-out method we randomly divide data set into two parts.\n",
    "Where the one part is used for learning the model and other for testing.\n",
    "In practice, we usually take 70-30 proportion of data set for training and testing respectively.\n",
    "Scikit learn provides inbuilt function that randomly divide data set into training and test data\n",
    "samples based on the split entered by the user. Each training and test set should include \n",
    "information on indicator and predictor variables.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9b424",
   "metadata": {},
   "source": [
    "# Loading train_test_split library from scikit learn for Hold-Out enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78d1d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # using scikit learn for hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3d7dcf",
   "metadata": {},
   "source": [
    "# Creating Hold-out enviornment for sample data set in scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df3ac4",
   "metadata": {},
   "source": [
    "# 1. Loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd3f7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading library\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b173727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "717e809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
      "        1.065e+03],\n",
      "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
      "        1.050e+03],\n",
      "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
      "        1.185e+03],\n",
      "       ...,\n",
      "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
      "        8.350e+02],\n",
      "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
      "        8.400e+02],\n",
      "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
      "        5.600e+02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2]), 'frame': None, 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'), 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n', 'feature_names': ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']}\n"
     ]
    }
   ],
   "source": [
    "print (dataset_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686f35f4",
   "metadata": {},
   "source": [
    "# 2. Creating Hold-out enviornment for built in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a139971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0 1 0 1 0 0 1 0 0 1 0 2 0 1 0 0 2 2 2 1 2 2 1 1 0 2 2 0 0 2 1 1 0 1 2\n",
      " 2 1 0 0 1 1 1 1 1 2 0 2 0 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "winedata_train, winedata_test, winetarget_train, winetarget_test = train_test_split(dataset_wine.data, dataset_wine.target, test_size=0.3)\n",
    "\n",
    "#The pair of arrays winedata_train and  winetarget_train will be used for learning\n",
    "#the sueprvised model. \n",
    "#Whereas, winedata_test and  winetarget_test for model testing\n",
    "print(winetarget_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c14e7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.182e+01 1.720e+00 1.880e+00 1.950e+01 8.600e+01 2.500e+00 1.640e+00\n",
      "  3.700e-01 1.420e+00 2.060e+00 9.400e-01 2.440e+00 4.150e+02]\n",
      " [1.345e+01 3.700e+00 2.600e+00 2.300e+01 1.110e+02 1.700e+00 9.200e-01\n",
      "  4.300e-01 1.460e+00 1.068e+01 8.500e-01 1.560e+00 6.950e+02]\n",
      " [1.406e+01 2.150e+00 2.610e+00 1.760e+01 1.210e+02 2.600e+00 2.510e+00\n",
      "  3.100e-01 1.250e+00 5.050e+00 1.060e+00 3.580e+00 1.295e+03]\n",
      " [1.164e+01 2.060e+00 2.460e+00 2.160e+01 8.400e+01 1.950e+00 1.690e+00\n",
      "  4.800e-01 1.350e+00 2.800e+00 1.000e+00 2.750e+00 6.800e+02]\n",
      " [1.356e+01 1.730e+00 2.460e+00 2.050e+01 1.160e+02 2.960e+00 2.780e+00\n",
      "  2.000e-01 2.450e+00 6.250e+00 9.800e-01 3.030e+00 1.120e+03]\n",
      " [1.200e+01 9.200e-01 2.000e+00 1.900e+01 8.600e+01 2.420e+00 2.260e+00\n",
      "  3.000e-01 1.430e+00 2.500e+00 1.380e+00 3.120e+00 2.780e+02]\n",
      " [1.377e+01 1.900e+00 2.680e+00 1.710e+01 1.150e+02 3.000e+00 2.790e+00\n",
      "  3.900e-01 1.680e+00 6.300e+00 1.130e+00 2.930e+00 1.375e+03]\n",
      " [1.483e+01 1.640e+00 2.170e+00 1.400e+01 9.700e+01 2.800e+00 2.980e+00\n",
      "  2.900e-01 1.980e+00 5.200e+00 1.080e+00 2.850e+00 1.045e+03]\n",
      " [1.145e+01 2.400e+00 2.420e+00 2.000e+01 9.600e+01 2.900e+00 2.790e+00\n",
      "  3.200e-01 1.830e+00 3.250e+00 8.000e-01 3.390e+00 6.250e+02]\n",
      " [1.382e+01 1.750e+00 2.420e+00 1.400e+01 1.110e+02 3.880e+00 3.740e+00\n",
      "  3.200e-01 1.870e+00 7.050e+00 1.010e+00 3.260e+00 1.190e+03]\n",
      " [1.422e+01 3.990e+00 2.510e+00 1.320e+01 1.280e+02 3.000e+00 3.040e+00\n",
      "  2.000e-01 2.080e+00 5.100e+00 8.900e-01 3.530e+00 7.600e+02]\n",
      " [1.243e+01 1.530e+00 2.290e+00 2.150e+01 8.600e+01 2.740e+00 3.150e+00\n",
      "  3.900e-01 1.770e+00 3.940e+00 6.900e-01 2.840e+00 3.520e+02]\n",
      " [1.351e+01 1.800e+00 2.650e+00 1.900e+01 1.100e+02 2.350e+00 2.530e+00\n",
      "  2.900e-01 1.540e+00 4.200e+00 1.100e+00 2.870e+00 1.095e+03]\n",
      " [1.251e+01 1.240e+00 2.250e+00 1.750e+01 8.500e+01 2.000e+00 5.800e-01\n",
      "  6.000e-01 1.250e+00 5.450e+00 7.500e-01 1.510e+00 6.500e+02]\n",
      " [1.368e+01 1.830e+00 2.360e+00 1.720e+01 1.040e+02 2.420e+00 2.690e+00\n",
      "  4.200e-01 1.970e+00 3.840e+00 1.230e+00 2.870e+00 9.900e+02]\n",
      " [1.305e+01 3.860e+00 2.320e+00 2.250e+01 8.500e+01 1.650e+00 1.590e+00\n",
      "  6.100e-01 1.620e+00 4.800e+00 8.400e-01 2.010e+00 5.150e+02]\n",
      " [1.420e+01 1.760e+00 2.450e+00 1.520e+01 1.120e+02 3.270e+00 3.390e+00\n",
      "  3.400e-01 1.970e+00 6.750e+00 1.050e+00 2.850e+00 1.450e+03]\n",
      " [1.383e+01 1.570e+00 2.620e+00 2.000e+01 1.150e+02 2.950e+00 3.400e+00\n",
      "  4.000e-01 1.720e+00 6.600e+00 1.130e+00 2.570e+00 1.130e+03]\n",
      " [1.225e+01 4.720e+00 2.540e+00 2.100e+01 8.900e+01 1.380e+00 4.700e-01\n",
      "  5.300e-01 8.000e-01 3.850e+00 7.500e-01 1.270e+00 7.200e+02]\n",
      " [1.388e+01 5.040e+00 2.230e+00 2.000e+01 8.000e+01 9.800e-01 3.400e-01\n",
      "  4.000e-01 6.800e-01 4.900e+00 5.800e-01 1.330e+00 4.150e+02]\n",
      " [1.316e+01 3.570e+00 2.150e+00 2.100e+01 1.020e+02 1.500e+00 5.500e-01\n",
      "  4.300e-01 1.300e+00 4.000e+00 6.000e-01 1.680e+00 8.300e+02]\n",
      " [1.237e+01 1.210e+00 2.560e+00 1.810e+01 9.800e+01 2.420e+00 2.650e+00\n",
      "  3.700e-01 2.080e+00 4.600e+00 1.190e+00 2.300e+00 6.780e+02]\n",
      " [1.362e+01 4.950e+00 2.350e+00 2.000e+01 9.200e+01 2.000e+00 8.000e-01\n",
      "  4.700e-01 1.020e+00 4.400e+00 9.100e-01 2.050e+00 5.500e+02]\n",
      " [1.281e+01 2.310e+00 2.400e+00 2.400e+01 9.800e+01 1.150e+00 1.090e+00\n",
      "  2.700e-01 8.300e-01 5.700e+00 6.600e-01 1.360e+00 5.600e+02]\n",
      " [1.386e+01 1.510e+00 2.670e+00 2.500e+01 8.600e+01 2.950e+00 2.860e+00\n",
      "  2.100e-01 1.870e+00 3.380e+00 1.360e+00 3.160e+00 4.100e+02]\n",
      " [1.264e+01 1.360e+00 2.020e+00 1.680e+01 1.000e+02 2.020e+00 1.410e+00\n",
      "  5.300e-01 6.200e-01 5.750e+00 9.800e-01 1.590e+00 4.500e+02]\n",
      " [1.307e+01 1.500e+00 2.100e+00 1.550e+01 9.800e+01 2.400e+00 2.640e+00\n",
      "  2.800e-01 1.370e+00 3.700e+00 1.180e+00 2.690e+00 1.020e+03]\n",
      " [1.317e+01 2.590e+00 2.370e+00 2.000e+01 1.200e+02 1.650e+00 6.800e-01\n",
      "  5.300e-01 1.460e+00 9.300e+00 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.373e+01 4.360e+00 2.260e+00 2.250e+01 8.800e+01 1.280e+00 4.700e-01\n",
      "  5.200e-01 1.150e+00 6.620e+00 7.800e-01 1.750e+00 5.200e+02]\n",
      " [1.305e+01 1.730e+00 2.040e+00 1.240e+01 9.200e+01 2.720e+00 3.270e+00\n",
      "  1.700e-01 2.910e+00 7.200e+00 1.120e+00 2.910e+00 1.150e+03]\n",
      " [1.410e+01 2.160e+00 2.300e+00 1.800e+01 1.050e+02 2.950e+00 3.320e+00\n",
      "  2.200e-01 2.380e+00 5.750e+00 1.250e+00 3.170e+00 1.510e+03]\n",
      " [1.378e+01 2.760e+00 2.300e+00 2.200e+01 9.000e+01 1.350e+00 6.800e-01\n",
      "  4.100e-01 1.030e+00 9.580e+00 7.000e-01 1.680e+00 6.150e+02]\n",
      " [1.247e+01 1.520e+00 2.200e+00 1.900e+01 1.620e+02 2.500e+00 2.270e+00\n",
      "  3.200e-01 3.280e+00 2.600e+00 1.160e+00 2.630e+00 9.370e+02]\n",
      " [1.200e+01 1.510e+00 2.420e+00 2.200e+01 8.600e+01 1.450e+00 1.250e+00\n",
      "  5.000e-01 1.630e+00 3.600e+00 1.050e+00 2.650e+00 4.500e+02]\n",
      " [1.348e+01 1.810e+00 2.410e+00 2.050e+01 1.000e+02 2.700e+00 2.980e+00\n",
      "  2.600e-01 1.860e+00 5.100e+00 1.040e+00 3.470e+00 9.200e+02]\n",
      " [1.181e+01 2.120e+00 2.740e+00 2.150e+01 1.340e+02 1.600e+00 9.900e-01\n",
      "  1.400e-01 1.560e+00 2.500e+00 9.500e-01 2.260e+00 6.250e+02]\n",
      " [1.270e+01 3.550e+00 2.360e+00 2.150e+01 1.060e+02 1.700e+00 1.200e+00\n",
      "  1.700e-01 8.400e-01 5.000e+00 7.800e-01 1.290e+00 6.000e+02]\n",
      " [1.287e+01 4.610e+00 2.480e+00 2.150e+01 8.600e+01 1.700e+00 6.500e-01\n",
      "  4.700e-01 8.600e-01 7.650e+00 5.400e-01 1.860e+00 6.250e+02]\n",
      " [1.229e+01 3.170e+00 2.210e+00 1.800e+01 8.800e+01 2.850e+00 2.990e+00\n",
      "  4.500e-01 2.810e+00 2.300e+00 1.420e+00 2.830e+00 4.060e+02]\n",
      " [1.350e+01 1.810e+00 2.610e+00 2.000e+01 9.600e+01 2.530e+00 2.610e+00\n",
      "  2.800e-01 1.660e+00 3.520e+00 1.120e+00 3.820e+00 8.450e+02]\n",
      " [1.285e+01 1.600e+00 2.520e+00 1.780e+01 9.500e+01 2.480e+00 2.370e+00\n",
      "  2.600e-01 1.460e+00 3.930e+00 1.090e+00 3.630e+00 1.015e+03]\n",
      " [1.252e+01 2.430e+00 2.170e+00 2.100e+01 8.800e+01 2.550e+00 2.270e+00\n",
      "  2.600e-01 1.220e+00 2.000e+00 9.000e-01 2.780e+00 3.250e+02]\n",
      " [1.182e+01 1.470e+00 1.990e+00 2.080e+01 8.600e+01 1.980e+00 1.600e+00\n",
      "  3.000e-01 1.530e+00 1.950e+00 9.500e-01 3.330e+00 4.950e+02]\n",
      " [1.222e+01 1.290e+00 1.940e+00 1.900e+01 9.200e+01 2.360e+00 2.040e+00\n",
      "  3.900e-01 2.080e+00 2.700e+00 8.600e-01 3.020e+00 3.120e+02]\n",
      " [1.237e+01 1.630e+00 2.300e+00 2.450e+01 8.800e+01 2.220e+00 2.450e+00\n",
      "  4.000e-01 1.900e+00 2.120e+00 8.900e-01 2.780e+00 3.420e+02]\n",
      " [1.208e+01 2.080e+00 1.700e+00 1.750e+01 9.700e+01 2.230e+00 2.170e+00\n",
      "  2.600e-01 1.400e+00 3.300e+00 1.270e+00 2.960e+00 7.100e+02]\n",
      " [1.348e+01 1.670e+00 2.640e+00 2.250e+01 8.900e+01 2.600e+00 1.100e+00\n",
      "  5.200e-01 2.290e+00 1.175e+01 5.700e-01 1.780e+00 6.200e+02]\n",
      " [1.363e+01 1.810e+00 2.700e+00 1.720e+01 1.120e+02 2.850e+00 2.910e+00\n",
      "  3.000e-01 1.460e+00 7.300e+00 1.280e+00 2.880e+00 1.310e+03]\n",
      " [1.349e+01 3.590e+00 2.190e+00 1.950e+01 8.800e+01 1.620e+00 4.800e-01\n",
      "  5.800e-01 8.800e-01 5.700e+00 8.100e-01 1.820e+00 5.800e+02]\n",
      " [1.422e+01 1.700e+00 2.300e+00 1.630e+01 1.180e+02 3.200e+00 3.000e+00\n",
      "  2.600e-01 2.030e+00 6.380e+00 9.400e-01 3.310e+00 9.700e+02]\n",
      " [1.303e+01 9.000e-01 1.710e+00 1.600e+01 8.600e+01 1.950e+00 2.030e+00\n",
      "  2.400e-01 1.460e+00 4.600e+00 1.190e+00 2.480e+00 3.920e+02]\n",
      " [1.371e+01 5.650e+00 2.450e+00 2.050e+01 9.500e+01 1.680e+00 6.100e-01\n",
      "  5.200e-01 1.060e+00 7.700e+00 6.400e-01 1.740e+00 7.400e+02]\n",
      " [1.279e+01 2.670e+00 2.480e+00 2.200e+01 1.120e+02 1.480e+00 1.360e+00\n",
      "  2.400e-01 1.260e+00 1.080e+01 4.800e-01 1.470e+00 4.800e+02]\n",
      " [1.336e+01 2.560e+00 2.350e+00 2.000e+01 8.900e+01 1.400e+00 5.000e-01\n",
      "  3.700e-01 6.400e-01 5.600e+00 7.000e-01 2.470e+00 7.800e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(winedata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95b10626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.236e+01 3.830e+00 2.380e+00 ... 5.600e-01 1.580e+00 5.200e+02]\n",
      " [1.208e+01 1.390e+00 2.500e+00 ... 9.300e-01 3.190e+00 3.850e+02]\n",
      " [1.340e+01 4.600e+00 2.860e+00 ... 6.700e-01 1.920e+00 6.300e+02]\n",
      " ...\n",
      " [1.390e+01 1.680e+00 2.120e+00 ... 9.100e-01 3.330e+00 9.850e+02]\n",
      " [1.234e+01 2.450e+00 2.460e+00 ... 8.000e-01 3.380e+00 4.380e+02]\n",
      " [1.358e+01 1.660e+00 2.360e+00 ... 1.090e+00 2.880e+00 1.515e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(winedata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a169f555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 1 1 0 2 2 0 1 2 1 0 0 1 0 1 2 0 2 1 0 1 1 1 0 1 1 2 1 0 1 2 2 0 0 0\n",
      " 1 2 1 1 0 0 1 1 2 2 0 2 0 2 1 0 0 2 2 0 1 0 2 2 1 0 1 1 1 0 1 1 1 2 1 0 0\n",
      " 1 1 2 2 1 0 0 0 1 1 0 1 1 1 1 2 0 0 0 0 2 2 1 1 0 1 1 2 1 2 1 2 1 1 0 1 2\n",
      " 0 0 2 1 0 2 1 1 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(winetarget_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef636336",
   "metadata": {},
   "source": [
    "# Creating Hold-out enviornment for user defined data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921ea8d",
   "metadata": {},
   "source": [
    "# 1. Import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5cb53c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e054f",
   "metadata": {},
   "source": [
    "# 2. Load user specific data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77c70547",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcv</th>\n",
       "      <th>alkphos</th>\n",
       "      <th>sgpt</th>\n",
       "      <th>sgot</th>\n",
       "      <th>gammagt</th>\n",
       "      <th>drink</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcv  alkphos  sgpt  sgot  gammagt  drink  target\n",
       "0   85       92    45    27       31    0.0       1\n",
       "1   85       64    59    32       23    0.0       2\n",
       "2   86       54    33    16       54    0.0       2\n",
       "3   91       78    34    24       36    0.0       2\n",
       "4   87       70    12    28       10    0.0       2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data set from local machine. The data set on predicting liver disorder.\n",
    "My_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "342abd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcv</th>\n",
       "      <th>alkphos</th>\n",
       "      <th>sgpt</th>\n",
       "      <th>sgot</th>\n",
       "      <th>gammagt</th>\n",
       "      <th>drink</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>99</td>\n",
       "      <td>75</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>96</td>\n",
       "      <td>69</td>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "      <td>203</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>98</td>\n",
       "      <td>77</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>89</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>91</td>\n",
       "      <td>68</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>57</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mcv  alkphos  sgpt  sgot  gammagt  drink  target\n",
       "0     85       92    45    27       31    0.0       1\n",
       "1     85       64    59    32       23    0.0       2\n",
       "2     86       54    33    16       54    0.0       2\n",
       "3     91       78    34    24       36    0.0       2\n",
       "4     87       70    12    28       10    0.0       2\n",
       "..   ...      ...   ...   ...      ...    ...     ...\n",
       "340   99       75    26    24       41   12.0       1\n",
       "341   96       69    53    43      203   12.0       2\n",
       "342   98       77    55    35       89   15.0       1\n",
       "343   91       68    27    26       14   16.0       1\n",
       "344   98       99    57    45       65   20.0       1\n",
       "\n",
       "[345 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a113e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcv</th>\n",
       "      <th>alkphos</th>\n",
       "      <th>sgpt</th>\n",
       "      <th>sgot</th>\n",
       "      <th>gammagt</th>\n",
       "      <th>drink</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcv  alkphos  sgpt  sgot  gammagt  drink  target\n",
       "0   85       92    45    27       31    0.0       1\n",
       "1   85       64    59    32       23    0.0       2\n",
       "2   86       54    33    16       54    0.0       2\n",
       "3   91       78    34    24       36    0.0       2\n",
       "4   87       70    12    28       10    0.0       2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b128d2a4",
   "metadata": {},
   "source": [
    "# 3. Creating Hold-out enviornment for user specific data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c14dc208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85. 92. 45. 27. 31.  0.]\n",
      " [85. 64. 59. 32. 23.  0.]\n",
      " [86. 54. 33. 16. 54.  0.]\n",
      " ...\n",
      " [98. 77. 55. 35. 89. 15.]\n",
      " [91. 68. 27. 26. 14. 16.]\n",
      " [98. 99. 57. 45. 65. 20.]]\n",
      "[1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 1 1 1 1\n",
      " 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 1 1 1 1 1 1 2 2 2 2 2 1 1 2 2\n",
      " 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1\n",
      " 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2\n",
      " 2 1 1 2 2 2 2 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# My_data contains all data points from My_data set from from first feature to  6th feature(indicator features)\n",
    "My_data = My_dataset.iloc[:,0:6].values\n",
    "print(My_data)\n",
    "\n",
    "# My_target contains class information which is 7th feature in the data set of all the data points in My_dataset\n",
    "\n",
    "My_target=My_dataset.iloc[:,6].values \n",
    "print(My_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bec89f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The pair of arrays liverdata_train and  livertarget_train will be used for learning the sueprvised model. \n",
    "# Whereas, liverdata_test and  livertarget_test for model testing\n",
    "\n",
    "liverdata_train, liverdata_test, livertarget_train, livertarget_test = train_test_split(My_data, My_target, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4644953f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97.   71.   29.   22.   52.    8. ]\n",
      " [ 89.   79.   17.   17.   16.    0.5]\n",
      " [ 92.   60.   23.   15.   19.    1. ]\n",
      " [ 97.   94.   43.   43.   82.    6. ]\n",
      " [ 98.   43.   35.   23.   69.    6. ]\n",
      " [ 91.  138.   45.   21.   48.   10. ]\n",
      " [ 92.   77.   86.   41.   31.   10. ]\n",
      " [ 88.   46.   29.   22.   18.    0.5]\n",
      " [ 65.   63.   19.   20.   14.    0.5]\n",
      " [ 90.   67.   10.   16.   16.    4. ]\n",
      " [ 86.   77.   25.   19.   18.    0.5]\n",
      " [ 85.   58.   83.   49.   51.    3. ]\n",
      " [ 88.   37.    9.   15.   16.    6. ]\n",
      " [ 92.   87.   57.   25.   44.    6. ]\n",
      " [ 90.   74.   19.   14.   22.    4. ]\n",
      " [ 82.   55.   18.   23.   44.    8. ]\n",
      " [ 84.   88.   28.   25.   35.    0.5]\n",
      " [ 89.   63.   24.   29.   29.    6. ]\n",
      " [ 98.   57.   31.   34.   73.   10. ]\n",
      " [ 88.   69.   70.   24.   64.    2. ]\n",
      " [ 92.  108.   53.   33.   94.   12. ]\n",
      " [ 98.   58.   33.   21.   28.    2. ]\n",
      " [ 88.   67.   21.   11.   11.    0.5]\n",
      " [ 90.   52.   10.   17.   12.    5. ]\n",
      " [ 90.   57.   31.   18.   37.    4. ]\n",
      " [ 90.   63.   45.   24.   85.    1. ]\n",
      " [ 87.   92.   21.   22.   37.    1. ]\n",
      " [ 98.   55.   13.   17.   17.    0. ]\n",
      " [ 89.   52.   13.   24.   15.    0.5]\n",
      " [ 92.   95.   85.   48.  200.    8. ]\n",
      " [ 91.   80.   37.   23.   27.    4. ]\n",
      " [ 88.   47.   35.   26.   33.    3. ]\n",
      " [ 92.   67.   15.   14.   14.    6. ]\n",
      " [ 90.   76.   37.   19.   50.    6. ]\n",
      " [ 79.   39.   14.   19.    9.    0.5]\n",
      " [ 98.   99.   57.   45.   65.   20. ]\n",
      " [ 84.   83.   20.   25.    7.    3. ]\n",
      " [ 92.   57.   64.   36.   90.    0.5]\n",
      " [ 86.   66.   28.   24.   21.    2. ]\n",
      " [ 92.   80.   10.   26.   20.    6. ]\n",
      " [ 92.   73.   33.   34.  115.    5. ]\n",
      " [ 86.   44.   24.   15.   18.    2. ]\n",
      " [ 86.   54.   33.   16.   54.    0. ]\n",
      " [ 91.   54.   25.   22.   35.    4. ]\n",
      " [ 91.   64.   21.   17.   26.    3. ]\n",
      " [ 92.   41.   37.   22.   37.   10. ]\n",
      " [ 93.   87.   18.   17.   26.    2. ]\n",
      " [ 89.   76.   14.   21.   24.    4. ]\n",
      " [ 98.   77.   55.   35.   89.   15. ]\n",
      " [ 91.   60.   32.   14.    8.    1. ]\n",
      " [ 91.   72.  155.   68.   82.    0.5]\n",
      " [ 93.   50.   18.   25.   17.    6. ]\n",
      " [ 91.   78.   34.   24.   36.    0. ]\n",
      " [ 94.   48.   11.   23.   43.    0.5]\n",
      " [ 85.  119.   30.   26.   17.    0.5]\n",
      " [ 91.  105.   40.   26.   56.    0.5]\n",
      " [ 94.   91.   27.   20.   15.    0.5]\n",
      " [ 93.   59.   17.   20.   14.    8. ]\n",
      " [ 91.   99.   42.   33.   16.    2. ]\n",
      " [ 87.   57.   30.   30.   22.    0.5]\n",
      " [ 96.   55.   48.   39.   42.    4. ]\n",
      " [ 88.   47.   33.   26.   29.    2. ]\n",
      " [ 90.   61.   28.   29.   31.    2. ]\n",
      " [ 90.  134.   14.   20.   14.    4. ]\n",
      " [ 88.   85.   14.   15.   10.    2. ]\n",
      " [ 92.   53.   51.   33.   92.    6. ]\n",
      " [ 90.   84.   18.   23.   13.    4. ]\n",
      " [ 90.   87.   19.   25.   19.    0.5]\n",
      " [ 93.   65.   28.   22.   10.    1. ]\n",
      " [ 87.   70.   12.   28.   10.    0. ]\n",
      " [ 78.   69.   24.   18.   31.    0.5]\n",
      " [ 97.   80.   17.   20.   53.    8. ]\n",
      " [ 86.   55.   29.   35.  108.    4. ]\n",
      " [ 86.   62.   29.   21.   26.    4. ]\n",
      " [ 85.   65.   23.   29.   15.    0.5]\n",
      " [ 94.  117.   77.   56.   52.    4. ]\n",
      " [ 90.   80.   19.   14.   42.    2. ]\n",
      " [ 85.   62.   15.   13.   22.    0.5]\n",
      " [ 86.   79.   28.   16.   17.    0.5]\n",
      " [ 92.   79.   22.   20.   11.    3. ]\n",
      " [ 92.   57.   21.   23.   22.    5. ]\n",
      " [ 90.   79.   18.   15.   24.    0.5]\n",
      " [ 92.   66.   21.   16.   33.    5. ]\n",
      " [ 86.   58.   16.   23.   23.    0.5]\n",
      " [ 94.   75.   20.   25.   38.    0.5]\n",
      " [ 90.   73.   24.   23.   11.    0.5]\n",
      " [ 92.   93.   22.   28.  123.    9. ]\n",
      " [ 85.   50.   12.   18.   14.    7. ]\n",
      " [ 87.   41.   31.   19.   16.    0.5]\n",
      " [ 90.   67.   77.   39.  114.    8. ]\n",
      " [ 88.   62.   20.   17.    9.    0.5]\n",
      " [ 89.   67.   23.   16.   10.    0.5]\n",
      " [ 92.   58.   14.   16.   13.    0.5]\n",
      " [ 94.   56.   30.   18.   27.    0.5]\n",
      " [ 91.   86.   52.   47.   52.    4. ]\n",
      " [ 96.   67.   29.   20.   11.    0.5]\n",
      " [ 92.   60.   30.   27.  297.    2. ]\n",
      " [ 83.   68.   17.   20.   71.    0.5]\n",
      " [ 87.   90.   43.   28.  156.    2. ]\n",
      " [ 85.   60.   17.   21.   14.    4. ]\n",
      " [ 85.   51.   26.   24.   23.    1. ]\n",
      " [ 94.   43.  154.   82.  121.    4. ]\n",
      " [ 94.   91.   30.   26.   25.    2. ]\n",
      " [ 87.   59.   37.   27.   34.    2. ]]\n"
     ]
    }
   ],
   "source": [
    "print(liverdata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d566d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 2 1 1 2 2 2 1 2 2 2 2 2 2 2 2 1 2 1 1 2 2 2 2 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 2 1 1 1 2 2 2 2 2 1 2 2 1 1 1 1 2 1 2 2 2\n",
      " 2 2 1 2 1 1 2 2 1 2 2 1 1 2 1 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(livertarget_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e39cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8d63731",
   "metadata": {},
   "source": [
    "# Learning SVM training and Testing using Hold-Out method\n",
    "\n",
    "# The code below demonstrates how SVM model is trained and tested under Hold-Out method. For better understanding, codes below explains building and testing SVM model on data set supported in scikit learn and user specific data set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4854174b",
   "metadata": {},
   "source": [
    "# 1. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2035e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets # imports built in data sets supported in scikit learn \n",
    "from sklearn import svm #imports SVM classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split # using scikit learn for hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059a1ec",
   "metadata": {},
   "source": [
    "# loding data  set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "257cc031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loding lod wine data set\n",
    "dataset_wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fdb614",
   "metadata": {},
   "source": [
    "# Creating hold out inviornmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f17c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "winedata_train, winedata_test, winetarget_train, winetarget_test = train_test_split(dataset_wine.data, dataset_wine.target, test_size=0.3)\n",
    "\n",
    "\n",
    "#The pair of arrays winedata_train and  winetarget_train will be used for learning\n",
    "#the sueprvised model. \n",
    "#Whereas, winedata_test and  winetarget_test for model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329cedd8",
   "metadata": {},
   "source": [
    "# 4.  Building SVM model \n",
    "\n",
    "We will use training data set created in step 3 for model training(or learning). The supervised model we will be building now is Support Vector Machines(SVM). SVM by theory supports different types of kernels such as, linear, polynomial and radial basis. Where linear kernel is suitable for linearly separable problems whereas, other for non-linearly separable problems. For building SVM model, we try with different types of kernel to discover best kernel for given problem based on performance of model on unknown observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "172d188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier. The various kernel supported in scikit learn are linear, poly and rbf.\n",
    "\n",
    "SVMmodel_1 = svm.SVC(kernel='rbf') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "\n",
    "SVMfitted_1 = SVMmodel_1.fit(winedata_train, winetarget_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec20f3a5",
   "metadata": {},
   "source": [
    "#  Testing trained SVM model on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f3f4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Predict the response on the test data set\n",
    "\n",
    "SVM_predictions_1 = SVMfitted_1.predict((winedata_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3065b",
   "metadata": {},
   "source": [
    "# Evaluating the performance of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7664330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.0 %\n",
      "---------------\n",
      "Confusion matrix\n",
      "---------------\n",
      "[[17  0  2]\n",
      " [ 1 16  5]\n",
      " [ 1  4  8]]\n",
      "---------------\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.89      0.89      0.89        19\n",
      "     class 1       0.80      0.73      0.76        22\n",
      "     class 2       0.53      0.62      0.57        13\n",
      "\n",
      "    accuracy                           0.76        54\n",
      "   macro avg       0.74      0.75      0.74        54\n",
      "weighted avg       0.77      0.76      0.76        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing Model Accuracy\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(winetarget_test, SVM_predictions_1),2) * 100, \"%\")\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "# Printing confusion matrix\n",
    "\n",
    "print (\"Confusion matrix\")\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "print(metrics.confusion_matrix(winetarget_test, SVM_predictions_1))\n",
    "\n",
    "# Model detailed classification report\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "print(\"Classification report\", metrics.classification_report(winetarget_test, SVM_predictions_1,target_names =target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f04b37f",
   "metadata": {},
   "source": [
    "# SVM on user specific data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc02cf4",
   "metadata": {},
   "source": [
    "# 1. Loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "035cdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data set from local machine. The data set on predicting liver disorder.\n",
    "    \n",
    "My_dataset = pd.read_csv('C:/Users/Prince/Desktop/amity programing/CSV files/liver_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b6957d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcv</th>\n",
       "      <th>alkphos</th>\n",
       "      <th>sgpt</th>\n",
       "      <th>sgot</th>\n",
       "      <th>gammagt</th>\n",
       "      <th>drink</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>99</td>\n",
       "      <td>75</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>96</td>\n",
       "      <td>69</td>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "      <td>203</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>98</td>\n",
       "      <td>77</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>89</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>91</td>\n",
       "      <td>68</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>57</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mcv  alkphos  sgpt  sgot  gammagt  drink  target\n",
       "0     85       92    45    27       31    0.0       1\n",
       "1     85       64    59    32       23    0.0       2\n",
       "2     86       54    33    16       54    0.0       2\n",
       "3     91       78    34    24       36    0.0       2\n",
       "4     87       70    12    28       10    0.0       2\n",
       "..   ...      ...   ...   ...      ...    ...     ...\n",
       "340   99       75    26    24       41   12.0       1\n",
       "341   96       69    53    43      203   12.0       2\n",
       "342   98       77    55    35       89   15.0       1\n",
       "343   91       68    27    26       14   16.0       1\n",
       "344   98       99    57    45       65   20.0       1\n",
       "\n",
       "[345 rows x 7 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0778c684",
   "metadata": {},
   "source": [
    "# 2. Dividing data set into sets  of indicator and predictive variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e4eb038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85. 92. 45. 27. 31.  0.]\n",
      " [85. 64. 59. 32. 23.  0.]\n",
      " [86. 54. 33. 16. 54.  0.]\n",
      " ...\n",
      " [98. 77. 55. 35. 89. 15.]\n",
      " [91. 68. 27. 26. 14. 16.]\n",
      " [98. 99. 57. 45. 65. 20.]]\n",
      "[1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 1 1 1 1\n",
      " 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 1 1 1 1 1 1 2 2 2 2 2 1 1 2 2\n",
      " 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1\n",
      " 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2\n",
      " 2 1 1 2 2 2 2 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# My_data contains all data points from My_data set from from first feature to  6th feature(indicator features)\n",
    "My_data = My_dataset.iloc[:,0:6].values \n",
    "\n",
    "# My_target contains class information which is 7th feature in the data set of all the data points in My_dataset\n",
    "\n",
    "My_target=My_dataset.iloc[:,6].values \n",
    "\n",
    "print(My_data)\n",
    "print(My_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a64f4",
   "metadata": {},
   "source": [
    "# 3. Creating Hold-out enviornment for the data set in step above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b983e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The pair of arrays liverdata_train and  livertarget_train will be used for learning the sueprvised model. \n",
    "# Whereas, liverdata_test and  livertarget_test for model testing\n",
    "\n",
    "liverdata_train, liverdatatest, livertarget_train, livertarget_test = train_test_split(My_data, My_target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fec25d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84. 73. 46. 32. 39.  4.]\n",
      " [87. 59. 37. 27. 34.  2.]\n",
      " [91. 63. 17. 17. 46.  4.]\n",
      " ...\n",
      " [90. 63. 16. 21. 14.  1.]\n",
      " [88. 66. 23. 12. 15.  3.]\n",
      " [92. 65. 17. 25.  9.  2.]]\n"
     ]
    }
   ],
   "source": [
    "print(liverdata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8909bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97.   71.   29.   22.   52.    8. ]\n",
      " [ 89.   79.   17.   17.   16.    0.5]\n",
      " [ 92.   60.   23.   15.   19.    1. ]\n",
      " [ 97.   94.   43.   43.   82.    6. ]\n",
      " [ 98.   43.   35.   23.   69.    6. ]\n",
      " [ 91.  138.   45.   21.   48.   10. ]\n",
      " [ 92.   77.   86.   41.   31.   10. ]\n",
      " [ 88.   46.   29.   22.   18.    0.5]\n",
      " [ 65.   63.   19.   20.   14.    0.5]\n",
      " [ 90.   67.   10.   16.   16.    4. ]\n",
      " [ 86.   77.   25.   19.   18.    0.5]\n",
      " [ 85.   58.   83.   49.   51.    3. ]\n",
      " [ 88.   37.    9.   15.   16.    6. ]\n",
      " [ 92.   87.   57.   25.   44.    6. ]\n",
      " [ 90.   74.   19.   14.   22.    4. ]\n",
      " [ 82.   55.   18.   23.   44.    8. ]\n",
      " [ 84.   88.   28.   25.   35.    0.5]\n",
      " [ 89.   63.   24.   29.   29.    6. ]\n",
      " [ 98.   57.   31.   34.   73.   10. ]\n",
      " [ 88.   69.   70.   24.   64.    2. ]\n",
      " [ 92.  108.   53.   33.   94.   12. ]\n",
      " [ 98.   58.   33.   21.   28.    2. ]\n",
      " [ 88.   67.   21.   11.   11.    0.5]\n",
      " [ 90.   52.   10.   17.   12.    5. ]\n",
      " [ 90.   57.   31.   18.   37.    4. ]\n",
      " [ 90.   63.   45.   24.   85.    1. ]\n",
      " [ 87.   92.   21.   22.   37.    1. ]\n",
      " [ 98.   55.   13.   17.   17.    0. ]\n",
      " [ 89.   52.   13.   24.   15.    0.5]\n",
      " [ 92.   95.   85.   48.  200.    8. ]\n",
      " [ 91.   80.   37.   23.   27.    4. ]\n",
      " [ 88.   47.   35.   26.   33.    3. ]\n",
      " [ 92.   67.   15.   14.   14.    6. ]\n",
      " [ 90.   76.   37.   19.   50.    6. ]\n",
      " [ 79.   39.   14.   19.    9.    0.5]\n",
      " [ 98.   99.   57.   45.   65.   20. ]\n",
      " [ 84.   83.   20.   25.    7.    3. ]\n",
      " [ 92.   57.   64.   36.   90.    0.5]\n",
      " [ 86.   66.   28.   24.   21.    2. ]\n",
      " [ 92.   80.   10.   26.   20.    6. ]\n",
      " [ 92.   73.   33.   34.  115.    5. ]\n",
      " [ 86.   44.   24.   15.   18.    2. ]\n",
      " [ 86.   54.   33.   16.   54.    0. ]\n",
      " [ 91.   54.   25.   22.   35.    4. ]\n",
      " [ 91.   64.   21.   17.   26.    3. ]\n",
      " [ 92.   41.   37.   22.   37.   10. ]\n",
      " [ 93.   87.   18.   17.   26.    2. ]\n",
      " [ 89.   76.   14.   21.   24.    4. ]\n",
      " [ 98.   77.   55.   35.   89.   15. ]\n",
      " [ 91.   60.   32.   14.    8.    1. ]\n",
      " [ 91.   72.  155.   68.   82.    0.5]\n",
      " [ 93.   50.   18.   25.   17.    6. ]\n",
      " [ 91.   78.   34.   24.   36.    0. ]\n",
      " [ 94.   48.   11.   23.   43.    0.5]\n",
      " [ 85.  119.   30.   26.   17.    0.5]\n",
      " [ 91.  105.   40.   26.   56.    0.5]\n",
      " [ 94.   91.   27.   20.   15.    0.5]\n",
      " [ 93.   59.   17.   20.   14.    8. ]\n",
      " [ 91.   99.   42.   33.   16.    2. ]\n",
      " [ 87.   57.   30.   30.   22.    0.5]\n",
      " [ 96.   55.   48.   39.   42.    4. ]\n",
      " [ 88.   47.   33.   26.   29.    2. ]\n",
      " [ 90.   61.   28.   29.   31.    2. ]\n",
      " [ 90.  134.   14.   20.   14.    4. ]\n",
      " [ 88.   85.   14.   15.   10.    2. ]\n",
      " [ 92.   53.   51.   33.   92.    6. ]\n",
      " [ 90.   84.   18.   23.   13.    4. ]\n",
      " [ 90.   87.   19.   25.   19.    0.5]\n",
      " [ 93.   65.   28.   22.   10.    1. ]\n",
      " [ 87.   70.   12.   28.   10.    0. ]\n",
      " [ 78.   69.   24.   18.   31.    0.5]\n",
      " [ 97.   80.   17.   20.   53.    8. ]\n",
      " [ 86.   55.   29.   35.  108.    4. ]\n",
      " [ 86.   62.   29.   21.   26.    4. ]\n",
      " [ 85.   65.   23.   29.   15.    0.5]\n",
      " [ 94.  117.   77.   56.   52.    4. ]\n",
      " [ 90.   80.   19.   14.   42.    2. ]\n",
      " [ 85.   62.   15.   13.   22.    0.5]\n",
      " [ 86.   79.   28.   16.   17.    0.5]\n",
      " [ 92.   79.   22.   20.   11.    3. ]\n",
      " [ 92.   57.   21.   23.   22.    5. ]\n",
      " [ 90.   79.   18.   15.   24.    0.5]\n",
      " [ 92.   66.   21.   16.   33.    5. ]\n",
      " [ 86.   58.   16.   23.   23.    0.5]\n",
      " [ 94.   75.   20.   25.   38.    0.5]\n",
      " [ 90.   73.   24.   23.   11.    0.5]\n",
      " [ 92.   93.   22.   28.  123.    9. ]\n",
      " [ 85.   50.   12.   18.   14.    7. ]\n",
      " [ 87.   41.   31.   19.   16.    0.5]\n",
      " [ 90.   67.   77.   39.  114.    8. ]\n",
      " [ 88.   62.   20.   17.    9.    0.5]\n",
      " [ 89.   67.   23.   16.   10.    0.5]\n",
      " [ 92.   58.   14.   16.   13.    0.5]\n",
      " [ 94.   56.   30.   18.   27.    0.5]\n",
      " [ 91.   86.   52.   47.   52.    4. ]\n",
      " [ 96.   67.   29.   20.   11.    0.5]\n",
      " [ 92.   60.   30.   27.  297.    2. ]\n",
      " [ 83.   68.   17.   20.   71.    0.5]\n",
      " [ 87.   90.   43.   28.  156.    2. ]\n",
      " [ 85.   60.   17.   21.   14.    4. ]\n",
      " [ 85.   51.   26.   24.   23.    1. ]\n",
      " [ 94.   43.  154.   82.  121.    4. ]\n",
      " [ 94.   91.   30.   26.   25.    2. ]\n",
      " [ 87.   59.   37.   27.   34.    2. ]]\n"
     ]
    }
   ],
   "source": [
    "print(liverdata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "932ef48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 1 2 2 1 1 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 2 1 2\n",
      " 1 1 2 2 2 1 2 2 2 1 1 1 2 2 2 1 1 1 2 2 1 1 1 2 2 2 2 2 1 2 2 2 1 2 1 1 2\n",
      " 1 1 1 1 2 2 2 1 1 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 1 2 2 2 2 2 2 2 2 2\n",
      " 1 1 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 1 1 1 2 1 1 2 2 2 2 1 2 2 1 1 1 1 1\n",
      " 2 2 2 2 2 1 1 2 2 2 2 1 2 2 2 1 1 2 2 1 2 2 2 2 2 2 1 1 2 1 2 2 1 2 2 2 2\n",
      " 2 2 1 1 1 2 2 2 1 2 1 2 1 1 1 2 2 2 2 2 1 2 2 2 1 1 2 1 1 2 1 1 2 2 2 1 2\n",
      " 2 2 2 2 1 2 2 2 2 2 1 1 2 2 2 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(livertarget_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3e098bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 1 1 2 2 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 2 2 1 1 1 2 1 2 2 2 1 1 1 1 2 2 2 2 1 1 1 1 2 1 1 2 1 2 2 2 1 1 2 2 2 1\n",
      " 1 2 2 1 2 1 2 2 2 2 2 1 1 1 2 2 2 2 2 1 2 1 2 1 2 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(livertarget_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8be3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a svm Classifier. The various kernel supported in scikit learn are linear, poly and rbf.\n",
    "\n",
    "SVMmodel_2 = svm.SVC(kernel='rbf') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "\n",
    "SVMfitted_2 = SVMmodel_2.fit(liverdata_train, livertarget_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9db510",
   "metadata": {},
   "source": [
    "# 5. Testing trained SVM model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6fda1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Predict the response on the test data set\n",
    "\n",
    "SVM_predictions_2 = SVMfitted_2.predict((liverdata_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bdb546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.00000000000001 %\n",
      "---------------\n",
      "Confusion matrix\n",
      "---------------\n",
      "[[11 41]\n",
      " [ 6 46]]\n",
      "---------------\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "    disorder       0.65      0.21      0.32        52\n",
      "  nodisorder       0.53      0.88      0.66        52\n",
      "\n",
      "    accuracy                           0.55       104\n",
      "   macro avg       0.59      0.55      0.49       104\n",
      "weighted avg       0.59      0.55      0.49       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing Model Accuracy\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(livertarget_test, SVM_predictions_2),2) * 100, \"%\")\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "# Printing confusion matrix\n",
    "\n",
    "\n",
    "print (\"Confusion matrix\")\n",
    "\n",
    "print (\"---------------\")\n",
    "print(metrics.confusion_matrix(livertarget_test, SVM_predictions_2))\n",
    "\n",
    "\n",
    "# User specific target names   \n",
    "    \n",
    "target_names = ['disorder', 'nodisorder']\n",
    "\n",
    "# Model detailed classification report\n",
    "\n",
    "print (\"---------------\")\n",
    "print(\"Classification report\", metrics.classification_report(livertarget_test, SVM_predictions_2,target_names =target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4803f51",
   "metadata": {},
   "source": [
    "# Learning Decision tree training and Testing using Hold-Out method\n",
    "\n",
    "# The code below demonstrates how Decision tree model is trained and tested under Hold-Out method. For better understanding, codes below explains building and testing Decision tree model on data set supported in scikit learn and user specific data set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d62a6c",
   "metadata": {},
   "source": [
    "# 1. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ab15a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # imports pandas for data structure support\n",
    "from sklearn import datasets # imports built in data sets supported in scikit learn \n",
    "from sklearn import tree   # imports Decision tree classifier\n",
    "from sklearn import metrics # imports performance metrices\n",
    "from sklearn.model_selection import train_test_split # using scikit learn for hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0a8ef",
   "metadata": {},
   "source": [
    "# 2. Loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1710fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading load_wine() data set \n",
    "\n",
    "dataset_wine = datasets.load_wine()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e190a726",
   "metadata": {},
   "source": [
    "# 3. Creating Hold-out Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6695d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "winedata_train, winedata_test, winetarget_train, winetarget_test = train_test_split(dataset_wine.data, dataset_wine.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd94ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.336e+01 2.560e+00 2.350e+00 ... 7.000e-01 2.470e+00 7.800e+02]\n",
      " [1.299e+01 1.670e+00 2.600e+00 ... 1.310e+00 3.500e+00 9.850e+02]\n",
      " [1.307e+01 1.500e+00 2.100e+00 ... 1.180e+00 2.690e+00 1.020e+03]\n",
      " ...\n",
      " [1.182e+01 1.720e+00 1.880e+00 ... 9.400e-01 2.440e+00 4.150e+02]\n",
      " [1.251e+01 1.730e+00 1.980e+00 ... 1.040e+00 3.570e+00 6.720e+02]\n",
      " [1.182e+01 1.470e+00 1.990e+00 ... 9.500e-01 3.330e+00 4.950e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(winedata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a1d9412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.340e+01 3.910e+00 2.480e+00 2.300e+01 1.020e+02 1.800e+00 7.500e-01\n",
      "  4.300e-01 1.410e+00 7.300e+00 7.000e-01 1.560e+00 7.500e+02]\n",
      " [1.329e+01 1.970e+00 2.680e+00 1.680e+01 1.020e+02 3.000e+00 3.230e+00\n",
      "  3.100e-01 1.660e+00 6.000e+00 1.070e+00 2.840e+00 1.270e+03]\n",
      " [1.270e+01 3.550e+00 2.360e+00 2.150e+01 1.060e+02 1.700e+00 1.200e+00\n",
      "  1.700e-01 8.400e-01 5.000e+00 7.800e-01 1.290e+00 6.000e+02]\n",
      " [1.237e+01 1.630e+00 2.300e+00 2.450e+01 8.800e+01 2.220e+00 2.450e+00\n",
      "  4.000e-01 1.900e+00 2.120e+00 8.900e-01 2.780e+00 3.420e+02]\n",
      " [1.311e+01 1.010e+00 1.700e+00 1.500e+01 7.800e+01 2.980e+00 3.180e+00\n",
      "  2.600e-01 2.280e+00 5.300e+00 1.120e+00 3.180e+00 5.020e+02]\n",
      " [1.327e+01 4.280e+00 2.260e+00 2.000e+01 1.200e+02 1.590e+00 6.900e-01\n",
      "  4.300e-01 1.350e+00 1.020e+01 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.225e+01 1.730e+00 2.120e+00 1.900e+01 8.000e+01 1.650e+00 2.030e+00\n",
      "  3.700e-01 1.630e+00 3.400e+00 1.000e+00 3.170e+00 5.100e+02]\n",
      " [1.208e+01 1.130e+00 2.510e+00 2.400e+01 7.800e+01 2.000e+00 1.580e+00\n",
      "  4.000e-01 1.400e+00 2.200e+00 1.310e+00 2.720e+00 6.300e+02]\n",
      " [1.416e+01 2.510e+00 2.480e+00 2.000e+01 9.100e+01 1.680e+00 7.000e-01\n",
      "  4.400e-01 1.240e+00 9.700e+00 6.200e-01 1.710e+00 6.600e+02]\n",
      " [1.207e+01 2.160e+00 2.170e+00 2.100e+01 8.500e+01 2.600e+00 2.650e+00\n",
      "  3.700e-01 1.350e+00 2.760e+00 8.600e-01 3.280e+00 3.780e+02]\n",
      " [1.374e+01 1.670e+00 2.250e+00 1.640e+01 1.180e+02 2.600e+00 2.900e+00\n",
      "  2.100e-01 1.620e+00 5.850e+00 9.200e-01 3.200e+00 1.060e+03]\n",
      " [1.184e+01 8.900e-01 2.580e+00 1.800e+01 9.400e+01 2.200e+00 2.210e+00\n",
      "  2.200e-01 2.350e+00 3.050e+00 7.900e-01 3.080e+00 5.200e+02]\n",
      " [1.350e+01 1.810e+00 2.610e+00 2.000e+01 9.600e+01 2.530e+00 2.610e+00\n",
      "  2.800e-01 1.660e+00 3.520e+00 1.120e+00 3.820e+00 8.450e+02]\n",
      " [1.305e+01 3.860e+00 2.320e+00 2.250e+01 8.500e+01 1.650e+00 1.590e+00\n",
      "  6.100e-01 1.620e+00 4.800e+00 8.400e-01 2.010e+00 5.150e+02]\n",
      " [1.279e+01 2.670e+00 2.480e+00 2.200e+01 1.120e+02 1.480e+00 1.360e+00\n",
      "  2.400e-01 1.260e+00 1.080e+01 4.800e-01 1.470e+00 4.800e+02]\n",
      " [1.373e+01 1.500e+00 2.700e+00 2.250e+01 1.010e+02 3.000e+00 3.250e+00\n",
      "  2.900e-01 2.380e+00 5.700e+00 1.190e+00 2.710e+00 1.285e+03]\n",
      " [1.348e+01 1.670e+00 2.640e+00 2.250e+01 8.900e+01 2.600e+00 1.100e+00\n",
      "  5.200e-01 2.290e+00 1.175e+01 5.700e-01 1.780e+00 6.200e+02]\n",
      " [1.221e+01 1.190e+00 1.750e+00 1.680e+01 1.510e+02 1.850e+00 1.280e+00\n",
      "  1.400e-01 2.500e+00 2.850e+00 1.280e+00 3.070e+00 7.180e+02]\n",
      " [1.184e+01 2.890e+00 2.230e+00 1.800e+01 1.120e+02 1.720e+00 1.320e+00\n",
      "  4.300e-01 9.500e-01 2.650e+00 9.600e-01 2.520e+00 5.000e+02]\n",
      " [1.200e+01 3.430e+00 2.000e+00 1.900e+01 8.700e+01 2.000e+00 1.640e+00\n",
      "  3.700e-01 1.870e+00 1.280e+00 9.300e-01 3.050e+00 5.640e+02]\n",
      " [1.390e+01 1.680e+00 2.120e+00 1.600e+01 1.010e+02 3.100e+00 3.390e+00\n",
      "  2.100e-01 2.140e+00 6.100e+00 9.100e-01 3.330e+00 9.850e+02]\n",
      " [1.420e+01 1.760e+00 2.450e+00 1.520e+01 1.120e+02 3.270e+00 3.390e+00\n",
      "  3.400e-01 1.970e+00 6.750e+00 1.050e+00 2.850e+00 1.450e+03]\n",
      " [1.164e+01 2.060e+00 2.460e+00 2.160e+01 8.400e+01 1.950e+00 1.690e+00\n",
      "  4.800e-01 1.350e+00 2.800e+00 1.000e+00 2.750e+00 6.800e+02]\n",
      " [1.253e+01 5.510e+00 2.640e+00 2.500e+01 9.600e+01 1.790e+00 6.000e-01\n",
      "  6.300e-01 1.100e+00 5.000e+00 8.200e-01 1.690e+00 5.150e+02]\n",
      " [1.272e+01 1.810e+00 2.200e+00 1.880e+01 8.600e+01 2.200e+00 2.530e+00\n",
      "  2.600e-01 1.770e+00 3.900e+00 1.160e+00 3.140e+00 7.140e+02]\n",
      " [1.351e+01 1.800e+00 2.650e+00 1.900e+01 1.100e+02 2.350e+00 2.530e+00\n",
      "  2.900e-01 1.540e+00 4.200e+00 1.100e+00 2.870e+00 1.095e+03]\n",
      " [1.204e+01 4.300e+00 2.380e+00 2.200e+01 8.000e+01 2.100e+00 1.750e+00\n",
      "  4.200e-01 1.350e+00 2.600e+00 7.900e-01 2.570e+00 5.800e+02]\n",
      " [1.371e+01 1.860e+00 2.360e+00 1.660e+01 1.010e+02 2.610e+00 2.880e+00\n",
      "  2.700e-01 1.690e+00 3.800e+00 1.110e+00 4.000e+00 1.035e+03]\n",
      " [1.422e+01 3.990e+00 2.510e+00 1.320e+01 1.280e+02 3.000e+00 3.040e+00\n",
      "  2.000e-01 2.080e+00 5.100e+00 8.900e-01 3.530e+00 7.600e+02]\n",
      " [1.305e+01 1.770e+00 2.100e+00 1.700e+01 1.070e+02 3.000e+00 3.000e+00\n",
      "  2.800e-01 2.030e+00 5.040e+00 8.800e-01 3.350e+00 8.850e+02]\n",
      " [1.156e+01 2.050e+00 3.230e+00 2.850e+01 1.190e+02 3.180e+00 5.080e+00\n",
      "  4.700e-01 1.870e+00 6.000e+00 9.300e-01 3.690e+00 4.650e+02]\n",
      " [1.242e+01 2.550e+00 2.270e+00 2.200e+01 9.000e+01 1.680e+00 1.840e+00\n",
      "  6.600e-01 1.420e+00 2.700e+00 8.600e-01 3.300e+00 3.150e+02]\n",
      " [1.145e+01 2.400e+00 2.420e+00 2.000e+01 9.600e+01 2.900e+00 2.790e+00\n",
      "  3.200e-01 1.830e+00 3.250e+00 8.000e-01 3.390e+00 6.250e+02]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.162e+01 1.990e+00 2.280e+00 1.800e+01 9.800e+01 3.020e+00 2.260e+00\n",
      "  1.700e-01 1.350e+00 3.250e+00 1.160e+00 2.960e+00 3.450e+02]\n",
      " [1.334e+01 9.400e-01 2.360e+00 1.700e+01 1.100e+02 2.530e+00 1.300e+00\n",
      "  5.500e-01 4.200e-01 3.170e+00 1.020e+00 1.930e+00 7.500e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(winedata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b8af06d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 1 0 0 2 0 1 2 2 1 0 0 1 0 1 2 2 1 0 1 1 2 1 1 2 0 1 1 2 0 0 2 0 2 1\n",
      " 1 1 2 0 0 1 1 0 0 0 1 1 2 1 0 0 0 0 0 1 2 0 2 0 1 0 2 0 1 0 2 1 1 1 1 2 2\n",
      " 0 2 2 0 2 2 0 0 2 0 1 0 0 1 1 0 1 2 1 0 2 0 1 1 1 0 1 1 0 1 1 1 1 0 0 2 2\n",
      " 0 0 1 2 2 2 1 1 0 1 1 2 2 1 0 1 2 2 2 2 0 0 2 0 1 2 2 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(winetarget_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b71eaab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 1 1 2 1 1 2 1 0 1 0 1 2 0 2 1 1 1 0 0 1 2 1 0 1 0 0 0 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(winetarget_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc7894",
   "metadata": {},
   "source": [
    "# 4.  Building Decision tree model \n",
    "\n",
    "We will use training data set created in step 3 for model training(or learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a366393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Decision tree Classifier\n",
    "\n",
    "DTmodel_1 = tree.DecisionTreeClassifier() \n",
    "\n",
    "#Train the model using the training sets\n",
    "\n",
    "DTfitted_1 = DTmodel_1.fit(winedata_train, winetarget_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffcae7f",
   "metadata": {},
   "source": [
    "# 5. Testing trained Decision tree model on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df85703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Predict the response on the test data set\n",
    "\n",
    "DT_predictions_1 = DTfitted_1.predict((winedata_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8823ed7",
   "metadata": {},
   "source": [
    "# 6. Evaluating the performance of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a19a5180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.0 %\n",
      "---------------\n",
      "Confusion matrix\n",
      "---------------\n",
      "[[10  1  0]\n",
      " [ 1 16  1]\n",
      " [ 0  0  7]]\n",
      "---------------\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.91      0.91      0.91        11\n",
      "     class 1       0.94      0.89      0.91        18\n",
      "     class 2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.93      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing Model Accuracy\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(winetarget_test, DT_predictions_1),2) * 100, \"%\")\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "# Printing confusion matrix\n",
    "\n",
    "print (\"Confusion matrix\")\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "print(metrics.confusion_matrix(winetarget_test, DT_predictions_1))\n",
    "\n",
    "# Model detailed classification report\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "print(\"Classification report\", metrics.classification_report(winetarget_test, DT_predictions_1,target_names =target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78ce1f",
   "metadata": {},
   "source": [
    "# Decision Tree on user specific data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e6578",
   "metadata": {},
   "source": [
    "# 1. Loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34530eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mcv  alkphos  sgpt  sgot  gammagt  drink  target\n",
      "0     85       92    45    27       31    0.0       1\n",
      "1     85       64    59    32       23    0.0       2\n",
      "2     86       54    33    16       54    0.0       2\n",
      "3     91       78    34    24       36    0.0       2\n",
      "4     87       70    12    28       10    0.0       2\n",
      "..   ...      ...   ...   ...      ...    ...     ...\n",
      "340   99       75    26    24       41   12.0       1\n",
      "341   96       69    53    43      203   12.0       2\n",
      "342   98       77    55    35       89   15.0       1\n",
      "343   91       68    27    26       14   16.0       1\n",
      "344   98       99    57    45       65   20.0       1\n",
      "\n",
      "[345 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Loading data set from local machine. The data set on predicting liver disorder.\n",
    "    \n",
    "My_dataset = pd.read_csv('C:/Users/Prince/Desktop/amity programing/CSV files/liver_dataset.csv')\n",
    "print(My_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e849878e",
   "metadata": {},
   "source": [
    "# 2. Dividing data set into sets  of indicator and predictive variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a78eb02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My_data contains all data points from My_data set from from first feature to  6th feature(indicator features)\n",
    "My_data = My_dataset.iloc[:,0:6].values \n",
    "\n",
    "# My_target contains class information which is 7th feature in the data set of all the data points in My_dataset\n",
    "\n",
    "My_target=My_dataset.iloc[:,6].values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e820cc",
   "metadata": {},
   "source": [
    "# 3. Creating Hold-out enviornment for the data set in step above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78362112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The pair of arrays liverdata_train and  livertarget_train will be used for learning the sueprvised model. \n",
    "# Whereas, liverdata_test and  livertarget_test for model testing\n",
    "\n",
    "liverdata_train, liverdata_test, livertarget_train, livertarget_test = train_test_split(My_data, My_target, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf62b3",
   "metadata": {},
   "source": [
    "# 4.  Building Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3ca0683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DTmodel_2 = tree.DecisionTreeClassifier()  \n",
    "\n",
    "#Train the model using the training sets\n",
    "\n",
    "DTfitted_2 = DTmodel_2.fit(liverdata_train, livertarget_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b83c6",
   "metadata": {},
   "source": [
    "# 5. Testing trained Decision tree model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d5971305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Predict the response on the test data set\n",
    "\n",
    "DT_predictions_2 = DTfitted_2.predict((liverdata_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07718511",
   "metadata": {},
   "source": [
    "# 6. Evaluating the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7c264b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.0 %\n",
      "---------------\n",
      "Confusion matrix\n",
      "---------------\n",
      "[[31 15]\n",
      " [15 43]]\n",
      "---------------\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "    disorder       0.67      0.67      0.67        46\n",
      "  nodisorder       0.74      0.74      0.74        58\n",
      "\n",
      "    accuracy                           0.71       104\n",
      "   macro avg       0.71      0.71      0.71       104\n",
      "weighted avg       0.71      0.71      0.71       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing Model Accuracy\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(livertarget_test, DT_predictions_2),2) * 100, \"%\")\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "# Printing confusion matrix\n",
    "\n",
    "\n",
    "print (\"Confusion matrix\")\n",
    "\n",
    "print (\"---------------\")\n",
    "print(metrics.confusion_matrix(livertarget_test, DT_predictions_2))\n",
    "\n",
    "\n",
    "# User specific target names   \n",
    "    \n",
    "target_names = ['disorder', 'nodisorder']\n",
    "\n",
    "# Model detailed classification report\n",
    "\n",
    "print (\"---------------\")\n",
    "print(\"Classification report\", metrics.classification_report(livertarget_test, DT_predictions_2,target_names =target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6efdcfa",
   "metadata": {},
   "source": [
    "# Visualize Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8da05982",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-c656ad439931>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "\n",
    "from IPython.display import Image  \n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "99a4424d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pydotplus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-be9907bb4db7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Draw graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Show graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pydotplus' is not defined"
     ]
    }
   ],
   "source": [
    "# Create DOT data. The first argument in tree.export_graphviz is the model name, out_file is used to write \n",
    "# model into out_file, next parameters are information on indicator and predictive parameters \n",
    "\n",
    "dot_data = tree.export_graphviz(DTmodel_1, out_file=None, feature_names=dataset_wine.feature_names, class_names=dataset_wine.target_names)\n",
    "\n",
    "# Draw graph\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a4a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "646ff656",
   "metadata": {},
   "source": [
    "# Learning KNN training and Testing using Hold-Out method\n",
    "\n",
    "# The code below demonstrates how KNN model is trained and tested under Hold-Out method. For better understanding, codes below explains building and testing KNN model on data set supported in scikit learn and user specific data set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a134ccd",
   "metadata": {},
   "source": [
    "# 1. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "15393497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets # imports built in data sets supported in scikit learn \n",
    "from sklearn.neighbors import KNeighborsClassifier  # imports KNN classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split # using scikit learn for hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58ff46",
   "metadata": {},
   "source": [
    "# 2. Loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0f523a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading load_wine() data set \n",
    "\n",
    "dataset_wine = datasets.load_wine()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "18a24306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf09de6",
   "metadata": {},
   "source": [
    "# 3. Creating Hold-out Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9fd2f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "winedata_train, winedata_test, winetarget_train, winetarget_test = train_test_split(dataset_wine.data, dataset_wine.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d5d59158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.237e+01 1.630e+00 2.300e+00 ... 8.900e-01 2.780e+00 3.420e+02]\n",
      " [1.165e+01 1.670e+00 2.620e+00 ... 1.360e+00 3.210e+00 5.620e+02]\n",
      " [1.156e+01 2.050e+00 3.230e+00 ... 9.300e-01 3.690e+00 4.650e+02]\n",
      " ...\n",
      " [1.356e+01 1.730e+00 2.460e+00 ... 9.800e-01 3.030e+00 1.120e+03]\n",
      " [1.375e+01 1.730e+00 2.410e+00 ... 1.150e+00 2.900e+00 1.320e+03]\n",
      " [1.187e+01 4.310e+00 2.390e+00 ... 7.500e-01 3.640e+00 3.800e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(winedata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b9f97c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.243e+01 1.530e+00 2.290e+00 2.150e+01 8.600e+01 2.740e+00 3.150e+00\n",
      "  3.900e-01 1.770e+00 3.940e+00 6.900e-01 2.840e+00 3.520e+02]\n",
      " [1.200e+01 3.430e+00 2.000e+00 1.900e+01 8.700e+01 2.000e+00 1.640e+00\n",
      "  3.700e-01 1.870e+00 1.280e+00 9.300e-01 3.050e+00 5.640e+02]\n",
      " [1.200e+01 9.200e-01 2.000e+00 1.900e+01 8.600e+01 2.420e+00 2.260e+00\n",
      "  3.000e-01 1.430e+00 2.500e+00 1.380e+00 3.120e+00 2.780e+02]\n",
      " [1.371e+01 5.650e+00 2.450e+00 2.050e+01 9.500e+01 1.680e+00 6.100e-01\n",
      "  5.200e-01 1.060e+00 7.700e+00 6.400e-01 1.740e+00 7.400e+02]\n",
      " [1.305e+01 1.650e+00 2.550e+00 1.800e+01 9.800e+01 2.450e+00 2.430e+00\n",
      "  2.900e-01 1.440e+00 4.250e+00 1.120e+00 2.510e+00 1.105e+03]\n",
      " [1.430e+01 1.920e+00 2.720e+00 2.000e+01 1.200e+02 2.800e+00 3.140e+00\n",
      "  3.300e-01 1.970e+00 6.200e+00 1.070e+00 2.650e+00 1.280e+03]\n",
      " [1.386e+01 1.510e+00 2.670e+00 2.500e+01 8.600e+01 2.950e+00 2.860e+00\n",
      "  2.100e-01 1.870e+00 3.380e+00 1.360e+00 3.160e+00 4.100e+02]\n",
      " [1.229e+01 1.610e+00 2.210e+00 2.040e+01 1.030e+02 1.100e+00 1.020e+00\n",
      "  3.700e-01 1.460e+00 3.050e+00 9.060e-01 1.820e+00 8.700e+02]\n",
      " [1.229e+01 2.830e+00 2.220e+00 1.800e+01 8.800e+01 2.450e+00 2.250e+00\n",
      "  2.500e-01 1.990e+00 2.150e+00 1.150e+00 3.300e+00 2.900e+02]\n",
      " [1.207e+01 2.160e+00 2.170e+00 2.100e+01 8.500e+01 2.600e+00 2.650e+00\n",
      "  3.700e-01 1.350e+00 2.760e+00 8.600e-01 3.280e+00 3.780e+02]\n",
      " [1.373e+01 4.360e+00 2.260e+00 2.250e+01 8.800e+01 1.280e+00 4.700e-01\n",
      "  5.200e-01 1.150e+00 6.620e+00 7.800e-01 1.750e+00 5.200e+02]\n",
      " [1.358e+01 1.660e+00 2.360e+00 1.910e+01 1.060e+02 2.860e+00 3.190e+00\n",
      "  2.200e-01 1.950e+00 6.900e+00 1.090e+00 2.880e+00 1.515e+03]\n",
      " [1.282e+01 3.370e+00 2.300e+00 1.950e+01 8.800e+01 1.480e+00 6.600e-01\n",
      "  4.000e-01 9.700e-01 1.026e+01 7.200e-01 1.750e+00 6.850e+02]\n",
      " [1.264e+01 1.360e+00 2.020e+00 1.680e+01 1.000e+02 2.020e+00 1.410e+00\n",
      "  5.300e-01 6.200e-01 5.750e+00 9.800e-01 1.590e+00 4.500e+02]\n",
      " [1.251e+01 1.730e+00 1.980e+00 2.050e+01 8.500e+01 2.200e+00 1.920e+00\n",
      "  3.200e-01 1.480e+00 2.940e+00 1.040e+00 3.570e+00 6.720e+02]\n",
      " [1.225e+01 3.880e+00 2.200e+00 1.850e+01 1.120e+02 1.380e+00 7.800e-01\n",
      "  2.900e-01 1.140e+00 8.210e+00 6.500e-01 2.000e+00 8.550e+02]\n",
      " [1.362e+01 4.950e+00 2.350e+00 2.000e+01 9.200e+01 2.000e+00 8.000e-01\n",
      "  4.700e-01 1.020e+00 4.400e+00 9.100e-01 2.050e+00 5.500e+02]\n",
      " [1.293e+01 3.800e+00 2.650e+00 1.860e+01 1.020e+02 2.410e+00 2.410e+00\n",
      "  2.500e-01 1.980e+00 4.500e+00 1.030e+00 3.520e+00 7.700e+02]\n",
      " [1.162e+01 1.990e+00 2.280e+00 1.800e+01 9.800e+01 3.020e+00 2.260e+00\n",
      "  1.700e-01 1.350e+00 3.250e+00 1.160e+00 2.960e+00 3.450e+02]\n",
      " [1.330e+01 1.720e+00 2.140e+00 1.700e+01 9.400e+01 2.400e+00 2.190e+00\n",
      "  2.700e-01 1.350e+00 3.950e+00 1.020e+00 2.770e+00 1.285e+03]\n",
      " [1.236e+01 3.830e+00 2.380e+00 2.100e+01 8.800e+01 2.300e+00 9.200e-01\n",
      "  5.000e-01 1.040e+00 7.650e+00 5.600e-01 1.580e+00 5.200e+02]\n",
      " [1.416e+01 2.510e+00 2.480e+00 2.000e+01 9.100e+01 1.680e+00 7.000e-01\n",
      "  4.400e-01 1.240e+00 9.700e+00 6.200e-01 1.710e+00 6.600e+02]\n",
      " [1.208e+01 1.390e+00 2.500e+00 2.250e+01 8.400e+01 2.560e+00 2.290e+00\n",
      "  4.300e-01 1.040e+00 2.900e+00 9.300e-01 3.190e+00 3.850e+02]\n",
      " [1.253e+01 5.510e+00 2.640e+00 2.500e+01 9.600e+01 1.790e+00 6.000e-01\n",
      "  6.300e-01 1.100e+00 5.000e+00 8.200e-01 1.690e+00 5.150e+02]\n",
      " [1.252e+01 2.430e+00 2.170e+00 2.100e+01 8.800e+01 2.550e+00 2.270e+00\n",
      "  2.600e-01 1.220e+00 2.000e+00 9.000e-01 2.780e+00 3.250e+02]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.373e+01 1.500e+00 2.700e+00 2.250e+01 1.010e+02 3.000e+00 3.250e+00\n",
      "  2.900e-01 2.380e+00 5.700e+00 1.190e+00 2.710e+00 1.285e+03]\n",
      " [1.383e+01 1.650e+00 2.600e+00 1.720e+01 9.400e+01 2.450e+00 2.990e+00\n",
      "  2.200e-01 2.290e+00 5.600e+00 1.240e+00 3.370e+00 1.265e+03]\n",
      " [1.237e+01 1.210e+00 2.560e+00 1.810e+01 9.800e+01 2.420e+00 2.650e+00\n",
      "  3.700e-01 2.080e+00 4.600e+00 1.190e+00 2.300e+00 6.780e+02]\n",
      " [1.245e+01 3.030e+00 2.640e+00 2.700e+01 9.700e+01 1.900e+00 5.800e-01\n",
      "  6.300e-01 1.140e+00 7.500e+00 6.700e-01 1.730e+00 8.800e+02]\n",
      " [1.303e+01 9.000e-01 1.710e+00 1.600e+01 8.600e+01 1.950e+00 2.030e+00\n",
      "  2.400e-01 1.460e+00 4.600e+00 1.190e+00 2.480e+00 3.920e+02]\n",
      " [1.422e+01 1.700e+00 2.300e+00 1.630e+01 1.180e+02 3.200e+00 3.000e+00\n",
      "  2.600e-01 2.030e+00 6.380e+00 9.400e-01 3.310e+00 9.700e+02]\n",
      " [1.242e+01 1.610e+00 2.190e+00 2.250e+01 1.080e+02 2.000e+00 2.090e+00\n",
      "  3.400e-01 1.610e+00 2.060e+00 1.060e+00 2.960e+00 3.450e+02]\n",
      " [1.341e+01 3.840e+00 2.120e+00 1.880e+01 9.000e+01 2.450e+00 2.680e+00\n",
      "  2.700e-01 1.480e+00 4.280e+00 9.100e-01 3.000e+00 1.035e+03]\n",
      " [1.272e+01 1.750e+00 2.280e+00 2.250e+01 8.400e+01 1.380e+00 1.760e+00\n",
      "  4.800e-01 1.630e+00 3.300e+00 8.800e-01 2.420e+00 4.880e+02]\n",
      " [1.394e+01 1.730e+00 2.270e+00 1.740e+01 1.080e+02 2.880e+00 3.540e+00\n",
      "  3.200e-01 2.080e+00 8.900e+00 1.120e+00 3.100e+00 1.260e+03]\n",
      " [1.196e+01 1.090e+00 2.300e+00 2.100e+01 1.010e+02 3.380e+00 2.140e+00\n",
      "  1.300e-01 1.650e+00 3.210e+00 9.900e-01 3.130e+00 8.860e+02]\n",
      " [1.419e+01 1.590e+00 2.480e+00 1.650e+01 1.080e+02 3.300e+00 3.930e+00\n",
      "  3.200e-01 1.860e+00 8.700e+00 1.230e+00 2.820e+00 1.680e+03]\n",
      " [1.438e+01 1.870e+00 2.380e+00 1.200e+01 1.020e+02 3.300e+00 3.640e+00\n",
      "  2.900e-01 2.960e+00 7.500e+00 1.200e+00 3.000e+00 1.547e+03]\n",
      " [1.145e+01 2.400e+00 2.420e+00 2.000e+01 9.600e+01 2.900e+00 2.790e+00\n",
      "  3.200e-01 1.830e+00 3.250e+00 8.000e-01 3.390e+00 6.250e+02]\n",
      " [1.242e+01 2.550e+00 2.270e+00 2.200e+01 9.000e+01 1.680e+00 1.840e+00\n",
      "  6.600e-01 1.420e+00 2.700e+00 8.600e-01 3.300e+00 3.150e+02]\n",
      " [1.421e+01 4.040e+00 2.440e+00 1.890e+01 1.110e+02 2.850e+00 2.650e+00\n",
      "  3.000e-01 1.250e+00 5.240e+00 8.700e-01 3.330e+00 1.080e+03]\n",
      " [1.182e+01 1.470e+00 1.990e+00 2.080e+01 8.600e+01 1.980e+00 1.600e+00\n",
      "  3.000e-01 1.530e+00 1.950e+00 9.500e-01 3.330e+00 4.950e+02]\n",
      " [1.208e+01 1.830e+00 2.320e+00 1.850e+01 8.100e+01 1.600e+00 1.500e+00\n",
      "  5.200e-01 1.640e+00 2.400e+00 1.080e+00 2.270e+00 4.800e+02]\n",
      " [1.272e+01 1.810e+00 2.200e+00 1.880e+01 8.600e+01 2.200e+00 2.530e+00\n",
      "  2.600e-01 1.770e+00 3.900e+00 1.160e+00 3.140e+00 7.140e+02]\n",
      " [1.410e+01 2.160e+00 2.300e+00 1.800e+01 1.050e+02 2.950e+00 3.320e+00\n",
      "  2.200e-01 2.380e+00 5.750e+00 1.250e+00 3.170e+00 1.510e+03]\n",
      " [1.402e+01 1.680e+00 2.210e+00 1.600e+01 9.600e+01 2.650e+00 2.330e+00\n",
      "  2.600e-01 1.980e+00 4.700e+00 1.040e+00 3.590e+00 1.035e+03]\n",
      " [1.349e+01 1.660e+00 2.240e+00 2.400e+01 8.700e+01 1.880e+00 1.840e+00\n",
      "  2.700e-01 1.030e+00 3.740e+00 9.800e-01 2.780e+00 4.720e+02]\n",
      " [1.328e+01 1.640e+00 2.840e+00 1.550e+01 1.100e+02 2.600e+00 2.680e+00\n",
      "  3.400e-01 1.360e+00 4.600e+00 1.090e+00 2.780e+00 8.800e+02]\n",
      " [1.307e+01 1.500e+00 2.100e+00 1.550e+01 9.800e+01 2.400e+00 2.640e+00\n",
      "  2.800e-01 1.370e+00 3.700e+00 1.180e+00 2.690e+00 1.020e+03]\n",
      " [1.422e+01 3.990e+00 2.510e+00 1.320e+01 1.280e+02 3.000e+00 3.040e+00\n",
      "  2.000e-01 2.080e+00 5.100e+00 8.900e-01 3.530e+00 7.600e+02]\n",
      " [1.184e+01 8.900e-01 2.580e+00 1.800e+01 9.400e+01 2.200e+00 2.210e+00\n",
      "  2.200e-01 2.350e+00 3.050e+00 7.900e-01 3.080e+00 5.200e+02]\n",
      " [1.176e+01 2.680e+00 2.920e+00 2.000e+01 1.030e+02 1.750e+00 2.030e+00\n",
      "  6.000e-01 1.050e+00 3.800e+00 1.230e+00 2.500e+00 6.070e+02]\n",
      " [1.372e+01 1.430e+00 2.500e+00 1.670e+01 1.080e+02 3.400e+00 3.670e+00\n",
      "  1.900e-01 2.040e+00 6.800e+00 8.900e-01 2.870e+00 1.285e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(winedata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b3e102f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 2 0 2 2 2 2 0 1 0 0 2 2 1 0 2 2 2 2 1 2 0 1 1 2 0 1 1 1 0 2 2 2 1\n",
      " 0 0 1 0 0 1 1 1 2 1 2 2 1 2 2 0 1 1 0 0 1 2 1 0 2 1 2 0 0 1 2 1 2 1 1 1 1\n",
      " 0 1 2 2 0 1 2 1 2 0 2 1 0 0 1 1 0 0 2 1 1 0 2 2 0 1 0 1 0 0 1 0 2 1 1 0 2\n",
      " 2 1 0 2 2 1 1 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(winetarget_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f913caf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 0 0 1 1 1 1 2 0 2 1 1 2 2 0 1 0 2 2 1 2 1 0 0 0 1 2 1 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(winetarget_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc4b8d",
   "metadata": {},
   "source": [
    "# 4.  Building KNN model \n",
    "\n",
    "We will use training data set created in step 3 for model training(or learning). The supervised model we will be building now is KNN classifier. KNN classifier requires user to specify number of nearest neighbor to train the model.  Here, user can try different values of K to test the performance of the classifier. If user does not specify the value of K then, the model takes the default value of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6a3a0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNN Classifier. The KNeighborsClassifier function takes value of k.\n",
    "KNNnmodel_1 = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "#Train the model using the training sets\n",
    "KNNfitted_1 = KNNnmodel_1.fit(winedata_train, winetarget_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e3c0a",
   "metadata": {},
   "source": [
    "# 5. Testing trained KNN model on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "504d6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response on the test data set\n",
    "KNN_predictions_1 = KNNfitted_1.predict((winedata_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59309111",
   "metadata": {},
   "source": [
    "# 6. Evaluating the performance of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f2e11a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.0 %\n",
      "---------------\n",
      "Confusion matrix\n",
      "---------------\n",
      "[[18  1  1]\n",
      " [ 2 20  3]\n",
      " [ 2  4  3]]\n",
      "---------------\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.82      0.90      0.86        20\n",
      "     class 1       0.80      0.80      0.80        25\n",
      "     class 2       0.43      0.33      0.38         9\n",
      "\n",
      "    accuracy                           0.76        54\n",
      "   macro avg       0.68      0.68      0.68        54\n",
      "weighted avg       0.74      0.76      0.75        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing Model Accuracy\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(winetarget_test, KNN_predictions_1),2) * 100, \"%\")\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "# Printing confusion matrix\n",
    "\n",
    "print (\"Confusion matrix\")\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "print(metrics.confusion_matrix(winetarget_test, KNN_predictions_1))\n",
    "\n",
    "# Model detailed classification report\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "print(\"Classification report\", metrics.classification_report(winetarget_test, KNN_predictions_1,target_names =target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba783e",
   "metadata": {},
   "source": [
    "# KNN on user specific data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78b154",
   "metadata": {},
   "source": [
    "# 1. Loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3db51903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data set from local machine\n",
    "My_dataset = pd.read_csv('C:/Users/Prince/Desktop/amity programing/CSV files/liver_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a68172a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcv</th>\n",
       "      <th>alkphos</th>\n",
       "      <th>sgpt</th>\n",
       "      <th>sgot</th>\n",
       "      <th>gammagt</th>\n",
       "      <th>drink</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcv  alkphos  sgpt  sgot  gammagt  drink  target\n",
       "0   85       92    45    27       31    0.0       1\n",
       "1   85       64    59    32       23    0.0       2\n",
       "2   86       54    33    16       54    0.0       2\n",
       "3   91       78    34    24       36    0.0       2\n",
       "4   87       70    12    28       10    0.0       2"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6fa90",
   "metadata": {},
   "source": [
    "# 2. Dividing data set into sets  of indicator and predictive variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dc7c1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My_data contains all data points from My_data set from from first feature to  6th feature(indicator features)\n",
    "My_data = My_dataset.iloc[:,0:6].values\n",
    "\n",
    "# My_target contains class information which is 7th feature in the data set of all the data points in My_dataset\n",
    "My_target = My_dataset.iloc[:,6].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43360202",
   "metadata": {},
   "source": [
    "# 3. Creating Hold-out enviornment for the data set in step above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7ca4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The pair of arrays liverdata_train and  livertarget_train will be used for learning the sueprvised model. \n",
    "# Whereas, liverdata_test and  livertarget_test for model testing\n",
    "\n",
    "liverdata_train, liverdata_test, livertarget_train, livertarget_test = train_test_split(My_data, My_target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9aba8105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 91.   60.   32.   14.    8.    1. ]\n",
      " [ 91.   63.   17.   17.   46.    4. ]\n",
      " [ 91.   96.   35.   22.  135.    0.5]\n",
      " ...\n",
      " [ 90.   62.   22.   21.   21.    8. ]\n",
      " [ 85.   62.   15.   13.   22.    0.5]\n",
      " [ 95.   50.   29.   25.   50.    0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(liverdata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1e31b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 83.   54.   27.   15.   12.    0.5]\n",
      " [ 98.   74.  148.   75.  159.    0.5]\n",
      " [ 89.   82.   33.   32.   18.    0.5]\n",
      " [ 89.   35.   27.   29.   17.    4. ]\n",
      " [ 95.   73.   20.   25.  225.    8. ]\n",
      " [ 96.   44.   42.   23.   73.    8. ]\n",
      " [ 90.   61.   28.   29.   31.    2. ]\n",
      " [ 85.  119.   30.   26.   17.    0.5]\n",
      " [ 95.   93.   21.   27.   47.    6. ]\n",
      " [ 92.   79.   22.   20.   11.    3. ]\n",
      " [ 86.  109.   16.   22.   28.    6. ]\n",
      " [ 91.   44.   18.   18.   23.    2. ]\n",
      " [ 87.   90.   43.   28.  156.    2. ]\n",
      " [ 84.   83.   20.   25.    7.    3. ]\n",
      " [ 83.   45.   19.   21.   13.    4. ]\n",
      " [ 94.   43.  154.   82.  121.    4. ]\n",
      " [ 90.   80.   19.   14.   42.    2. ]\n",
      " [ 91.   57.   31.   23.   42.    0.5]\n",
      " [ 92.   62.   37.   21.   36.    6. ]\n",
      " [ 96.   69.   53.   43.  203.   12. ]\n",
      " [ 82.   72.   31.   20.   84.    3. ]\n",
      " [ 93.   84.   58.   47.   62.    7. ]\n",
      " [ 79.  101.   17.   27.   23.    4. ]\n",
      " [ 91.   68.   14.   20.   19.    4. ]\n",
      " [ 97.   93.   21.   20.   68.    6. ]\n",
      " [ 85.   59.   25.   20.   25.    3. ]\n",
      " [ 92.   57.   64.   36.   90.    0.5]\n",
      " [ 87.   64.   16.   20.   24.    5. ]\n",
      " [ 88.   58.   31.   17.   17.    2. ]\n",
      " [ 87.   92.   21.   22.   37.    1. ]\n",
      " [ 91.   75.   24.   22.   11.    0.5]\n",
      " [ 86.   79.   37.   28.   14.    0.5]\n",
      " [ 97.   92.   22.   28.   49.   12. ]\n",
      " [ 65.   63.   19.   20.   14.    0.5]\n",
      " [ 85.   58.   18.   24.   16.    0.5]\n",
      " [ 86.   54.   20.   21.   16.    2. ]\n",
      " [ 90.   67.   77.   39.  114.    8. ]\n",
      " [ 92.   76.   31.   28.   41.    6. ]\n",
      " [ 89.   62.   42.   30.   20.    3. ]\n",
      " [ 94.  101.   41.   20.   53.    0.5]\n",
      " [ 91.   78.   20.   31.   18.    0.5]\n",
      " [ 90.   74.   19.   14.   22.    4. ]\n",
      " [ 88.   49.   20.   22.   19.    0.5]\n",
      " [ 84.   99.   33.   19.   26.    8. ]\n",
      " [ 90.   67.   35.   19.   35.    2. ]\n",
      " [ 91.   80.   37.   23.   27.    4. ]\n",
      " [ 87.   66.   27.   22.    9.    2. ]\n",
      " [ 94.   65.   22.   18.   11.    0.5]\n",
      " [ 94.   56.   30.   18.   27.    0.5]\n",
      " [ 92.  101.   34.   30.   64.    2. ]\n",
      " [ 87.   59.   15.   19.   12.    5. ]\n",
      " [ 92.   67.   15.   14.   14.    6. ]\n",
      " [ 90.   55.   20.   20.   16.    3. ]\n",
      " [ 84.   92.   68.   37.   44.    0.5]\n",
      " [ 85.   64.   24.   22.   11.    0.5]\n",
      " [102.   82.   34.   78.  203.    7. ]\n",
      " [ 93.   59.   41.   30.   48.    1. ]\n",
      " [ 88.   67.   21.   11.   11.    0.5]\n",
      " [ 98.   43.   35.   23.   69.    6. ]\n",
      " [ 90.  134.   14.   20.   14.    4. ]\n",
      " [ 92.   66.   21.   16.   33.    5. ]\n",
      " [ 86.   79.   28.   16.   17.    0.5]\n",
      " [ 90.   64.   12.   17.   14.    0.5]\n",
      " [ 86.   55.   29.   35.  108.    4. ]\n",
      " [ 91.   52.   15.   22.   11.    0.5]\n",
      " [ 90.   79.   18.   15.   24.    0.5]\n",
      " [ 85.   92.   45.   27.   31.    0. ]\n",
      " [ 98.  101.   31.   26.   32.    6. ]\n",
      " [ 93.   77.   39.   37.  108.   16. ]\n",
      " [ 96.   70.   70.   26.   36.    6. ]\n",
      " [ 90.   70.   25.   23.  112.    5. ]\n",
      " [ 88.  122.   35.   29.   42.    0.5]\n",
      " [ 93.   65.   28.   22.   10.    1. ]\n",
      " [ 94.  116.   11.   33.   11.    0.5]\n",
      " [ 83.   70.   17.   19.   23.    4. ]\n",
      " [ 86.   58.   36.   27.   59.    0.5]\n",
      " [ 96.   55.   48.   39.   42.    4. ]\n",
      " [ 91.   54.   25.   22.   35.    4. ]\n",
      " [ 90.   87.   19.   25.   19.    0.5]\n",
      " [ 81.   41.   33.   27.   34.    1. ]\n",
      " [ 89.   67.    5.   17.   14.    1. ]\n",
      " [ 90.   63.   29.   23.   57.    2. ]\n",
      " [ 91.   62.   59.   47.   60.    8. ]\n",
      " [ 91.   63.   25.   26.   15.    6. ]\n",
      " [ 87.   71.   33.   20.   22.    2. ]\n",
      " [ 89.   74.   19.   23.   16.    0.5]\n",
      " [ 98.   77.   55.   35.   89.   15. ]\n",
      " [ 90.   63.   12.   26.   21.    6. ]\n",
      " [ 92.   87.   57.   25.   44.    6. ]\n",
      " [ 83.   78.   31.   19.  115.    1. ]\n",
      " [ 85.   85.   25.   26.   30.    0.5]\n",
      " [ 89.   79.   17.   17.   16.    0.5]\n",
      " [ 92.   80.   10.   26.   20.    6. ]\n",
      " [ 97.   62.   17.   13.    5.    0.5]\n",
      " [ 92.   61.   18.   13.   81.    3. ]\n",
      " [ 88.   56.   23.   18.   12.    0. ]\n",
      " [ 87.   59.   37.   27.   34.    2. ]\n",
      " [ 88.   80.   24.   25.   17.    4. ]\n",
      " [ 89.   68.   26.   39.   42.    0.5]\n",
      " [ 88.   81.   41.   27.   36.    0.5]\n",
      " [ 87.   41.   31.   19.   16.    0.5]\n",
      " [ 93.   99.   36.   34.   48.    6. ]\n",
      " [ 92.   54.   22.   20.    7.    0.5]\n",
      " [ 88.   57.    9.   15.   16.    2. ]]\n"
     ]
    }
   ],
   "source": [
    "print(liverdata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "67a1f9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 2 1 1 2 2 2 2 2 2 1 2 2 2 1 1 2 2 1 2 1 1 1 2 2 2 1 2 1 1 1 2 1 2 2\n",
      " 1 2 2 1 1 1 1 2 2 2 1 2 2 1 2 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1\n",
      " 2 1 1 2 2 2 1 2 1 1 1 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 1 1 1 2 2 1 1 2 1 2\n",
      " 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 1 2 1 2 1 2 2 1 2 1 2 1 2 1 1 1 2 1 1 1 2 2 1 2 1 1 2 2 1 2 2 1 2\n",
      " 2 1 1 1 2 2 2 2 2 1 2 2 1 2 2 1 2 2 2 2 1 2 2 2 1 2 2 1 2 1 1 2 1 1 2 1 1\n",
      " 2 2 1 2 1 2 1 2 2 2 2 2 1 2 1 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(livertarget_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c6199964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 2 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 1 1\n",
      " 2 1 2 1 2 2 1 1 1 1 1 2 2 2 1 1 2 2 2 2 1 2 2 1 1 2 2 2 2 1 1 1 1 2 2 1 1\n",
      " 2 2 2 1 1 1 2 1 2 1 1 2 1 2 2 2 2 1 1 1 2 1 2 2 2 2 1 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(livertarget_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f79a7ed",
   "metadata": {},
   "source": [
    "# 4.  Building KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "85392845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNN Classifier. The KNeighborsClassifier function takes value of k.\n",
    "KNNnmodel_2 = KNeighborsClassifier(n_neighbors = 4)\n",
    "\n",
    "#Train the model using the training sets\n",
    "KNNfitted_2 = KNNnmodel_2.fit(liverdata_train, livertarget_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a346f",
   "metadata": {},
   "source": [
    "# 5. Testing trained KNN model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6e36ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response on the test data set\n",
    "KNN_predictions_2 = KNNfitted_2.predict((liverdata_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b83945",
   "metadata": {},
   "source": [
    "# 6. Evaluating the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5800cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.0 %\n",
      "---------------\n",
      "Confusion matrix\n",
      "---------------\n",
      "[[28 18]\n",
      " [21 37]]\n",
      "---------------\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "    disorder       0.57      0.61      0.59        46\n",
      "  nodisorder       0.67      0.64      0.65        58\n",
      "\n",
      "    accuracy                           0.62       104\n",
      "   macro avg       0.62      0.62      0.62       104\n",
      "weighted avg       0.63      0.62      0.63       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing Model Accuracy\n",
    "\n",
    "print(\"Accuracy:\",round(metrics.accuracy_score(livertarget_test, KNN_predictions_2),2) * 100, \"%\")\n",
    "\n",
    "print (\"---------------\")\n",
    "\n",
    "# Printing confusion matrix\n",
    "\n",
    "\n",
    "print (\"Confusion matrix\")\n",
    "\n",
    "print (\"---------------\")\n",
    "print(metrics.confusion_matrix(livertarget_test, KNN_predictions_2))\n",
    "\n",
    "\n",
    "# User specific target names   \n",
    "    \n",
    "target_names = ['disorder', 'nodisorder']\n",
    "\n",
    "# Model detailed classification report\n",
    "\n",
    "print (\"---------------\")\n",
    "print(\"Classification report\", metrics.classification_report(livertarget_test, KNN_predictions_2,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6fdf69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
